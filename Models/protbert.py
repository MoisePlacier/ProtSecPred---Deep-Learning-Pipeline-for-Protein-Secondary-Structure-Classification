# protbert.py
# Objectif : Exemple complet de pipeline ProtBERT pour pr√©dire la structure secondaire

from transformers import AutoTokenizer, AutoModel
import torch
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings("ignore")

# MINI DATASET 

# S√©quences d'acides amin√©s et structures secondaires correspondantes
# H = h√©lice, E = feuillet, C = boucle
dataset = [
    {"sequence": "ACDEFGHIK", "labels": "CCCHHHHHH"},
    {"sequence": "LMNPQRSTV", "labels": "HHHHCCCCE"},
    {"sequence": "WYACDGHIK", "labels": "EEEHHHCCC"},
]

# CHARGER PROTBERT
print("Chargement de ProtBERT...")
tokenizer = AutoTokenizer.from_pretrained("Rostlab/prot_bert", do_lower_case=False)
model = AutoModel.from_pretrained("Rostlab/prot_bert")
model.eval()  # mode √©valuation (pas d'entra√Ænement du mod√®le de langage)


# FONCTION D‚ÄôEMBEDDING
def embed_sequence(seq):
    """Retourne les embeddings (vecteurs) d'une s√©quence avec ProtBERT"""
    seq = " ".join(list(seq))  # ProtBERT attend des acides amin√©s s√©par√©s par des espaces
    tokens = tokenizer(seq, return_tensors="pt")
    with torch.no_grad():
        output = model(**tokens)
    emb = output.last_hidden_state.squeeze(0)[1:-1]  # on retire les tokens sp√©ciaux [CLS], [SEP]
    return emb.numpy()  # (longueur de s√©quence, 1024)

# CR√âER X et y

X_list, y_list = [], []
print("G√©n√©ration des embeddings ProtBERT...")

for sample in dataset:
    emb = embed_sequence(sample["sequence"])
    labels = list(sample["labels"])
    # On ajoute les embeddings et leurs labels correspondants
    X_list.append(emb)
    y_list.extend(labels)

# Concat√©ner toutes les s√©quences (par position)
X = np.vstack(X_list)
y = np.array(y_list)
print(f"Embeddings g√©n√©r√©s : X = {X.shape}, y = {y.shape}")


# ENTRA√éNEMENT D'UN MODELE SIMPLE
print("Entra√Ænement d‚Äôun RandomForest...")
clf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)
clf.fit(X, y)
print("Mod√®le entra√Æn√©")


# PR√âDICTION SUR UNE NOUVELLE S√âQUENCE
test_seq = "ACDFGHIKL"
print(f"üîπ Pr√©diction sur nouvelle s√©quence : {test_seq}")

test_emb = embed_sequence(test_seq)
pred = clf.predict(test_emb)
print("Structure secondaire pr√©dite :", "".join(pred))


# √âVALUATION RAPIDE SUR LE TRAIN SET
y_pred_train = clf.predict(X)
acc = accuracy_score(y, y_pred_train)
print(f"Accuracy (train) = {acc:.2f}")
